{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T06:35:57.750791Z",
     "start_time": "2025-10-06T06:35:50.795460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.version.git_version)\n"
   ],
   "id": "569ade430948b42f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu129\n",
      "12.9\n",
      "a1cb3cc05d46d198467bebbb6e8fba50a325d4e7\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-06T06:36:04.734281Z",
     "start_time": "2025-10-06T06:36:03.558585Z"
    }
   },
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"PyTorch built with:\", torch.version.git_version)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce GTX 1650\n",
      "CUDA version: 12.9\n",
      "PyTorch built with: a1cb3cc05d46d198467bebbb6e8fba50a325d4e7\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "82023f488666ce1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T06:36:09.149275Z",
     "start_time": "2025-10-06T06:36:09.137279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(\"üöÄ CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"üß† GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"üíª CUDA version:\", torch.version.cuda)\n",
    "    print(\"üî• PyTorch built with:\", torch.version.git_version)\n",
    "    print(\"Memory allocated:\", round(torch.cuda.memory_allocated(0)/1024**2, 2), \"MB\")\n",
    "    print(\"Memory cached:\", round(torch.cuda.memory_reserved(0)/1024**2, 2), \"MB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not detected. Try reinstalling the correct build.\")\n"
   ],
   "id": "533dd03452c72af6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ CUDA available: True\n",
      "üß† GPU: NVIDIA GeForce GTX 1650\n",
      "üíª CUDA version: 12.9\n",
      "üî• PyTorch built with: a1cb3cc05d46d198467bebbb6e8fba50a325d4e7\n",
      "Memory allocated: 0.0 MB\n",
      "Memory cached: 0.0 MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T06:36:18.269755Z",
     "start_time": "2025-10-06T06:36:16.915609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch, time\n",
    "x = torch.randn(5000, 5000, device='cuda')\n",
    "y = torch.randn(5000, 5000, device='cuda')\n",
    "torch.cuda.synchronize()\n",
    "t0 = time.time()\n",
    "for _ in range(10):\n",
    "    z = x @ y\n",
    "torch.cuda.synchronize()\n",
    "print(\"Avg time per matmul:\", (time.time()-t0)/10, \"sec\")\n"
   ],
   "id": "ccfda400760c72b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg time per matmul: 0.11971290111541748 sec\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
